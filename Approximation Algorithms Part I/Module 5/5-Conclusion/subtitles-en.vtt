WEBVTT

1
00:00:00.025 --> 00:00:04.552
[SOUND] So, we have defined and

2
00:00:04.552 --> 00:00:13.254
analyzed an approximation algorithm for
multiway cut.

3
00:00:13.254 --> 00:00:15.670
What else can we say about this problem?

4
00:00:17.720 --> 00:00:22.110
First we had this cool
geometric embedding.

5
00:00:22.110 --> 00:00:25.500
To interpret the LP relaxation and

6
00:00:25.500 --> 00:00:30.570
then we used it for
inspiration to design our rounding.

7
00:00:30.570 --> 00:00:37.210
Can we get a better randomized rounding to
have a better approximation for multicut?

8
00:00:37.210 --> 00:00:42.570
Is it possible to get
better than 3/2- 1/k?

9
00:00:42.570 --> 00:00:45.520
Well, the answer is yes.

10
00:00:45.520 --> 00:00:50.951
For t to equal to 3 for example,
it's possible to get 12 11ths,

11
00:00:50.951 --> 00:00:56.588
by using the linear programming
relaxation to find a better rounding.

12
00:00:56.588 --> 00:01:01.927
And, so, instead of just using
these balls, we can represent

13
00:01:01.927 --> 00:01:09.000
the problem of finding a good randomized
rounding as a linear programing problem.

14
00:01:10.230 --> 00:01:14.710
Finding the right way to
do randomized rounding

15
00:01:14.710 --> 00:01:18.200
can be expressed as linear programming.

16
00:01:19.220 --> 00:01:24.210
So we round the LP relaxation
using a linear program.

17
00:01:24.210 --> 00:01:24.900
That's cool.

18
00:01:26.050 --> 00:01:28.150
And then, for larger k,

19
00:01:28.150 --> 00:01:32.650
the same method can also be used to
try to get a better approximation.

20
00:01:32.650 --> 00:01:36.882
It's possible to beat this
three-halves approximation.

21
00:01:36.882 --> 00:01:40.150
However, The problem is APX-hard.

22
00:01:40.150 --> 00:01:43.040
It is not possible to get 1 + epsilon.

23
00:01:43.040 --> 00:01:45.210
There is no approximation scheme for

24
00:01:45.210 --> 00:01:47.900
this problem if p is different from np,
of course.

25
00:01:50.120 --> 00:01:54.976
So let's look a little bit at the story
behind the story of the multi problem.

26
00:01:57.440 --> 00:02:02.433
The first paper that dealt with
approximation algorithms gave us

27
00:02:02.433 --> 00:02:05.800
a little bit of a story
about applications.

28
00:02:05.800 --> 00:02:09.851
This is what they said; they said,
this problem comes up in

29
00:02:09.851 --> 00:02:14.970
the minimization of communication
costs in parallel computing systems.

30
00:02:16.590 --> 00:02:21.660
It also comes up when you assign
program modules to processors.

31
00:02:21.660 --> 00:02:25.570
When you try to partition files
among the nodes of a network.

32
00:02:25.570 --> 00:02:30.920
When you try to assign users to computers
in a multicomputer environment.

33
00:02:30.920 --> 00:02:35.480
And when you try to partition the elements
of a circuit into the subcircuits,

34
00:02:35.480 --> 00:02:37.660
that will go on different chips.

35
00:02:37.660 --> 00:02:42.042
That problem, in a way,
is more geometric, so

36
00:02:42.042 --> 00:02:49.504
it is perhaps a little bit easier because
it's a more special case, if I may say.

37
00:02:49.504 --> 00:02:55.126
So this problem, variance problems come
up in a number of settings where you have

38
00:02:55.126 --> 00:03:01.010
to assign something to something else and
there's an underlying graph structure.

39
00:03:03.070 --> 00:03:06.779
Now, who started studying this from
the viewpoint of approximation algorithms?

40
00:03:09.230 --> 00:03:14.200
Here are the first people who designed the
basic algorithm we saw at the beginning

41
00:03:14.200 --> 00:03:15.440
of this chapter.

42
00:03:16.900 --> 00:03:20.920
Elias Dalhaus, David Johnson,
Mihalis Yannakakis,

43
00:03:20.920 --> 00:03:24.110
Christos Papadimitrou and Paul Seymour.

44
00:03:24.110 --> 00:03:28.340
They proved the APX hardness and
they gave the approximation with min cuts.

45
00:03:29.680 --> 00:03:32.070
Some of these names, you have seen before.

46
00:03:32.070 --> 00:03:36.210
These people are well known in
the field of approximation algorithms.

47
00:03:37.900 --> 00:03:42.296
Then, who came up with
the geometric representation?

48
00:03:44.240 --> 00:03:48.046
Calinescu, Karloff, and Rabani.

49
00:03:48.046 --> 00:03:52.130
They came up with a geometric embedding,
and how to use it.

50
00:03:52.130 --> 00:03:54.830
That is really cool I think.

51
00:03:54.830 --> 00:04:00.770
This is really the most novel idea
of this chapter in my opinion,

52
00:04:00.770 --> 00:04:04.646
and this is how they got the 3/2- 1/k.

53
00:04:06.530 --> 00:04:11.454
Further who came up with the ways
to improve this approximation by

54
00:04:11.454 --> 00:04:16.020
getting a better randomized
rounding by finding the correct

55
00:04:16.020 --> 00:04:18.629
rounding using a linear program?

56
00:04:18.629 --> 00:04:22.230
David Karger, Philip Klein, Mikkel Thorup,
Cliff Stein, and Neal Young.

57
00:04:23.660 --> 00:04:25.050
They got the 12/11.

58
00:04:26.220 --> 00:04:29.810
So these are the main steps

59
00:04:29.810 --> 00:04:33.940
of designing approximation algorithms for
the multi we cut problem.

60
00:04:35.570 --> 00:04:36.070
Now what?

61
00:04:37.100 --> 00:04:39.587
Well let's see.

62
00:04:39.587 --> 00:04:44.952
In the past five weeks we have studied
a number of techniques in the design of

63
00:04:44.952 --> 00:04:50.590
approximation algorithms rounding
the input in the way that maybe adaptive.

64
00:04:52.420 --> 00:04:57.810
Writing a linear programming relaxation
a tool we have studied at length.

65
00:04:57.810 --> 00:05:02.799
Randomized rounding some finds
a sophisticated version of randomized

66
00:05:02.799 --> 00:05:03.636
rounding.

67
00:05:03.636 --> 00:05:09.533
Probabilistic analysis techniques in
the context of set cover in particular,

68
00:05:09.533 --> 00:05:12.701
to try to prove that our result is good,
and

69
00:05:12.701 --> 00:05:17.700
your geometric interpretation
of the LP relaxation.

70
00:05:17.700 --> 00:05:20.810
This is already a good array of tools.

71
00:05:20.810 --> 00:05:25.140
This is starting to be a solid
knowledge of approximation algorithms.

72
00:05:25.140 --> 00:05:29.912
In terms of problems, what problems
have we studied in the past few weeks?

73
00:05:29.912 --> 00:05:34.583
Vertex cover, knapsack, bin packing,

74
00:05:34.583 --> 00:05:37.970
set cover, multi-way cut.

75
00:05:37.970 --> 00:05:42.586
Five basic foundational
problems of optimization.

76
00:05:43.760 --> 00:05:49.450
They are all and for
all of them we design good approximation.

77
00:05:49.450 --> 00:05:55.300
And each of them was an opportunity for
us to study a new technique either for

78
00:05:55.300 --> 00:06:01.520
designing approximation algorithms or for
analyzing the quality of the solution.

79
00:06:02.740 --> 00:06:04.490
So what's missing?

80
00:06:04.490 --> 00:06:08.430
Well, there are still a couple of
important techniques that are missing.

81
00:06:08.430 --> 00:06:13.065
If you want to discover them,
you'll have to take the follow-up course,

82
00:06:13.065 --> 00:06:15.505
Approximation Algorithms, Part II.

83
00:06:15.505 --> 00:06:18.991
In which, we will study LP duality,

84
00:06:18.991 --> 00:06:24.970
a fundamental basic tool
using linear programming.

85
00:06:24.970 --> 00:06:32.720
Primal dual algorithms using LP duality to
have efficient approximation algorithms.

86
00:06:32.720 --> 00:06:35.010
And some indefinite programming.

87
00:06:35.010 --> 00:06:39.940
A really powerful technique for
problems that were

88
00:06:39.940 --> 00:06:45.130
previously seen, seemed out of reach so
if you want to learn about these

89
00:06:45.130 --> 00:06:49.570
techniques take approximation algorithms
part two, I hope to see you there